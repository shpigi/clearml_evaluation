{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d52f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml.automation.controller import PipelineDecorator\n",
    "from clearml import TaskTypes\n",
    "\n",
    "\n",
    "@PipelineDecorator.component(\n",
    "    return_values=[\"the_dataset\"], cache=False, task_type=TaskTypes.data_processing\n",
    ")\n",
    "def make_new_dataset_component(project, i_dataset, num_samples_per_chunk=500):\n",
    "    from image_classifier_training import pipeline_functions\n",
    "    return pipeline_functions.make_new_dataset(project, i_dataset, num_samples_per_chunk=500)\n",
    "    \n",
    "\n",
    "\n",
    "@PipelineDecorator.component(\n",
    "    return_values=[\"run_model_path\", \"run_tb_path\"],\n",
    "    cache=False,\n",
    "    task_type=TaskTypes.training,\n",
    ")\n",
    "def train_image_classifier_component(\n",
    "    clearml_dataset, backbone_name, run_model_uri, run_tb_uri, local_data_path=\"/data\"\n",
    "):\n",
    "    from image_classifier_training import pipeline_functions\n",
    "\n",
    "    return pipeline_functions.train_image_classifier(\n",
    "        clearml_dataset,\n",
    "        backbone_name,\n",
    "        run_model_uri,\n",
    "        run_tb_uri,\n",
    "        local_data_path=\"/data\",\n",
    "    )\n",
    "\n",
    "\n",
    "from clearml import Task\n",
    "@PipelineDecorator.pipeline(\n",
    "    name=\"fastai_image_classification_pipeline\",\n",
    "    project=\"lavi-testing\",\n",
    "    version=\"0.2\",\n",
    "    multi_instance_support=True,\n",
    ")\n",
    "def fastai_image_classification_pipeline(run_id, i_dataset, backbone_name=\"resnet34\"):\n",
    "    from clearml import Task\n",
    "    from image_classifier_training import pipeline_functions\n",
    "    class TaskURIs:\n",
    "        def __init__(self, project, pipeline_name, run_id):\n",
    "            path_pref = f\"{project}/{pipeline_name}\"\n",
    "            self.tboard = f\"{path_pref}/tboard/{run_id}\"\n",
    "            self.models = f\"{path_pref}/models/{run_id}\"\n",
    "            self.evaluations = f\"{path_pref}/evaluations/{run_id}\"\n",
    "    project_name = \"lavi-testing\"\n",
    "    pipeline_name = \"fastai_image_classification\"\n",
    "    \n",
    "\n",
    "    pipeline_task = Task.current_task()\n",
    "    print(\"pipeline task=\", pipeline_task)\n",
    "    config = {\"run_id\": run_id}\n",
    "    config[\"backbone_name\"] = backbone_name\n",
    "    config[\"i_dataset\"] = backbone_name\n",
    "\n",
    "    print(\"run_id:\", run_id)\n",
    "\n",
    "    if pipeline_task:\n",
    "        config = pipeline_task.connect_configuration(config, name=\"run_config\")\n",
    "\n",
    "    print(\"make dataset\")\n",
    "    training_dataset = make_new_dataset_component(\n",
    "        project=project_name, i_dataset=i_dataset, num_samples_per_chunk=500\n",
    "    )\n",
    "    config[\"training_dataset\"] = {\n",
    "        \"id\": training_dataset.id,\n",
    "        \"name\": training_dataset.name,\n",
    "    }\n",
    "\n",
    "    run_uris = TaskURIs(\n",
    "        project=project_name, pipeline_name=pipeline_name, run_id=run_id\n",
    "    )\n",
    "\n",
    "    config[\"run_uris\"] = json.loads(json.dumps(vars(run_uris), default=str))\n",
    "\n",
    "    print(\"train model\")\n",
    "    run_model_path, run_tb_path = run_learner_path = train_image_classifier_component(\n",
    "        clearml_dataset=training_dataset,\n",
    "        backbone_name=backbone_name,\n",
    "        run_model_uri=run_uris.models,\n",
    "        run_tb_uri=run_uris.tboard,\n",
    "        local_data_path=\"/data\",\n",
    "    )\n",
    "    #     config[\"run_learner_path\"] = str(run_learner_path)\n",
    "\n",
    "    #     print(\"evaluate model\")\n",
    "    #     run_eval_path = eval_model(\n",
    "    #         run_learner_path,\n",
    "    #         run_dataset_path,\n",
    "    #         run_splits_path,\n",
    "    #         run_id,\n",
    "    #         task_paths.evaluations_path,\n",
    "    #     )\n",
    "    #     config[\"run_eval_path\"] = str(run_eval_path)\n",
    "    #     # clearml_task.close()\n",
    "\n",
    "    print(\"pipeline complete\")\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dbec344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=95c0e17390a6402daa89bee651cc0d50\n",
      "2022-07-09 20:19:29,808 - clearml.Task - INFO - No repository found, storing script code instead\n",
      "ClearML results page: https://app.clear.ml/projects/cdcb102e595545cc90e370e977ced98a/experiments/95c0e17390a6402daa89bee651cc0d50/output/log\n",
      "ClearML pipeline page: https://app.clear.ml/pipelines/cdcb102e595545cc90e370e977ced98a/experiments/95c0e17390a6402daa89bee651cc0d50\n",
      "pipeline task= <clearml.task.Task object at 0x7f40e0d41790>\n",
      "run_id: run_1\n",
      "make dataset\n",
      "Launching step [make_new_dataset_component]\n",
      "ClearML results page: https://app.clear.ml/projects/cdcb102e595545cc90e370e977ced98a/experiments/afeca009b496475c9d7680ba7d5c1cdc/output/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/tmp1bq7ohox.py\", line 25, in <module>\n",
      "    results = make_new_dataset_component(**kwargs)\n",
      "  File \"/tmp/tmp1bq7ohox.py\", line 6, in make_new_dataset_component\n",
      "    from image_classifier_training import pipeline_functions\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/clearml/binding/import_bind.py\", line 54, in __patched_import3\n",
      "    mod = builtins.__org_import__(\n",
      "ModuleNotFoundError: No module named 'image_classifier_training'\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/clearml/automation/controller.py\", line 3532, in sanitized_env\n",
      "    a_result = func(*a_args, **a_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/clearml/automation/controller.py\", line 3302, in internal_decorator\n",
      "    pipeline_result = func(**pipeline_kwargs)\n",
      "  File \"/tmp/ipykernel_1278/1638735983.py\", line 69, in fastai_image_classification_pipeline\n",
      "    \"id\": training_dataset.id,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/clearml/utilities/proxy_object.py\", line 330, in __getattribute__\n",
      "    return getattr(LazyEvalWrapper._load_object(self), attr)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/clearml/utilities/proxy_object.py\", line 349, in _load_object\n",
      "    obj = cb()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/clearml/automation/controller.py\", line 3101, in result_wrapper\n",
      "    raise ValueError(\n",
      "ValueError: Pipeline step \"make_new_dataset_component\", Task ID=afeca009b496475c9d7680ba7d5c1cdc failed\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "from datetime import datetime\n",
    "run_id = f\"run_{datetime.utcnow().strftime('%Y_%m_%dT%H_%M_%S.%f')[:-3]}\"\n",
    "PipelineDecorator.run_locally()\n",
    "fastai_image_classification_pipeline(run_id = \"run_1\", i_dataset=0, backbone_name=\"resnet34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef189b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TaskURIs:\n",
    "#     def __init__(self, project, pipeline_name, run_id):\n",
    "#         path_pref = f\"{project}/{pipeline_name}\"\n",
    "#         self.tboard = f\"{path_pref}/tboard/{run_id}\"\n",
    "#         self.models = f\"{path_pref}/models/{run_id}\"\n",
    "#         self.evaluations = f\"{path_pref}/evaluations/{run_id}\"\n",
    "\n",
    "# from datetime import datetime\n",
    "# pipeline_name = \"fastai_image_classification\"\n",
    "# run_id = f\"run_{datetime.utcnow().strftime('%Y_%m_%dT%H_%M_%S.%f')[:-3]}\"\n",
    "# run_uris= TaskURIs(project=\"lavi-tests\", pipeline_name=pipeline_name, run_id=run_id)\n",
    "# json.loads(json.dumps(vars(run_uris), default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c0c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e ./image_classifier_training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591f9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
