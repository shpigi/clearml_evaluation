{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_preparation import make_raw_data_and_eval_dataset\n",
    "# make_raw_data_and_eval_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d52f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml.automation.controller import PipelineDecorator\n",
    "from clearml import TaskTypes\n",
    "\n",
    "\n",
    "@PipelineDecorator.component(\n",
    "    return_values=[\"the_dataset\"],\n",
    "    cache=False,\n",
    "    task_type=TaskTypes.data_processing,\n",
    "    packages=[\n",
    "        \"clearml\",\n",
    "        \"tensorboard_logger\",\n",
    "        \"timm\",\n",
    "        \"fastai\",\n",
    "        \"torch==1.11.0\",\n",
    "        \"torchvision==0.12.0\",\n",
    "        \"protobuf==3.19.*\",\n",
    "        \"tensorboard\",\n",
    "        \"google-cloud-storage>=1.13.2\",\n",
    "    ],\n",
    "    repo=\"git@github.com:shpigi/clearml_evaluation.git\",\n",
    "    repo_branch=\"main\",\n",
    ")\n",
    "def make_new_dataset_component(\n",
    "    project, i_dataset: int, num_samples_per_chunk: int = 500\n",
    "):\n",
    "    import sys\n",
    "\n",
    "    sys.path.insert(0, \"/src/clearml_evaluation/\")\n",
    "    from image_classifier_training import pipeline_functions\n",
    "\n",
    "    return pipeline_functions.make_new_dataset(\n",
    "        project, i_dataset, num_samples_per_chunk=num_samples_per_chunk\n",
    "    )\n",
    "\n",
    "\n",
    "@PipelineDecorator.component(\n",
    "    return_values=[\"run_model_path\", \"run_tb_path\"],\n",
    "    cache=False,\n",
    "    task_type=TaskTypes.training,\n",
    "    packages=[\n",
    "        \"clearml\",\n",
    "        \"tensorboard_logger\",\n",
    "        \"timm\",\n",
    "        \"fastai\",\n",
    "        \"torch==1.11.0\",\n",
    "        \"torchvision==0.12.0\",\n",
    "        \"protobuf==3.19.*\",\n",
    "        \"tensorboard\",\n",
    "        \"google-cloud-storage>=1.13.2\",\n",
    "    ],\n",
    "    repo=\"git@github.com:shpigi/clearml_evaluation.git\",\n",
    "    repo_branch=\"main\",\n",
    ")\n",
    "def train_image_classifier_component(\n",
    "    clearml_dataset,\n",
    "    backbone_name,\n",
    "    image_resize: int,\n",
    "    batch_size: int,\n",
    "    run_model_uri,\n",
    "    run_tb_uri,\n",
    "    local_data_path,\n",
    "    num_epochs: int,\n",
    "):\n",
    "    import sys\n",
    "\n",
    "    sys.path.insert(0, \"/src/clearml_evaluation/\")\n",
    "    from image_classifier_training import pipeline_functions\n",
    "\n",
    "    run_model_path, run_tb_path = pipeline_functions.train_image_classifier(\n",
    "        clearml_dataset,\n",
    "        backbone_name,\n",
    "        image_resize,\n",
    "        batch_size,\n",
    "        run_model_uri,\n",
    "        run_tb_uri,\n",
    "        local_data_path,\n",
    "        num_epochs,\n",
    "    )\n",
    "    return run_model_path, run_tb_path\n",
    "\n",
    "\n",
    "@PipelineDecorator.component(\n",
    "    return_values=[\"run_eval_path\"],\n",
    "    cache=False,\n",
    "    task_type=TaskTypes.testing,\n",
    "    packages=[\n",
    "        \"clearml\",\n",
    "        \"tensorboard_logger\",\n",
    "        \"timm\",\n",
    "        \"fastai\",\n",
    "        \"torch==1.11.0\",\n",
    "        \"torchvision==0.12.0\",\n",
    "        \"protobuf==3.19.*\",\n",
    "        \"tensorboard\",\n",
    "        \"google-cloud-storage>=1.13.2\",\n",
    "    ],\n",
    "    repo=\"git@github.com:shpigi/clearml_evaluation.git\",\n",
    "    repo_branch=\"main\",\n",
    ")\n",
    "\n",
    "\n",
    "def eval_model_component(\n",
    "    run_learner_path,\n",
    "    run_id,\n",
    "    dataset_name,\n",
    "    dataset_project,\n",
    "    run_eval_uri,\n",
    "    image_resize:int,\n",
    "    batch_size:int,\n",
    "    local_data_path,\n",
    "):\n",
    "    import sys\n",
    "\n",
    "    sys.path.insert(0, \"/src/clearml_evaluation/\")\n",
    "    from image_classifier_training import pipeline_functions\n",
    "\n",
    "    return pipeline_functions.eval_model(\n",
    "        run_learner_path,\n",
    "        run_id,\n",
    "        dataset_name,\n",
    "        dataset_project,\n",
    "        run_eval_uri,\n",
    "        image_resize,\n",
    "        batch_size,\n",
    "        local_data_path,\n",
    "    )\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "\n",
    "@PipelineDecorator.pipeline(\n",
    "    name=\"fastai_image_classification_pipeline\",\n",
    "    project=\"lavi-testing\",\n",
    "    version=\"0.2\",\n",
    "    multi_instance_support=True,\n",
    ")\n",
    "def fastai_image_classification_pipeline(\n",
    "    run_id: str,\n",
    "    i_datasets: Tuple[int],\n",
    "    backbone_names: List[str],\n",
    "    image_resizes: List[int],\n",
    "    batch_sizes: List[int],\n",
    "    num_train_epochs: int,\n",
    "):\n",
    "    from clearml import Task\n",
    "    import json\n",
    "\n",
    "    class TaskURIs:\n",
    "        def __init__(self, project, pipeline_name, run_id):\n",
    "            path_pref = f\"{project}/{pipeline_name}\"\n",
    "            self.tboard = f\"{path_pref}/tboard/{run_id}\"\n",
    "            self.models = f\"{path_pref}/models/{run_id}\"\n",
    "            self.evaluations = f\"{path_pref}/evaluations/{run_id}\"\n",
    "\n",
    "    project_name = \"lavi-testing\"\n",
    "    pipeline_name = \"fastai_image_classification\"\n",
    "\n",
    "    pipeline_task = Task.current_task()\n",
    "    print(\"pipeline task=\", pipeline_task)\n",
    "    #     config = {\"run_id\": run_id}\n",
    "    #     config[\"backbone_name\"] = backbone_name\n",
    "    #     config[\"i_datasets\"] = i_datasets\n",
    "\n",
    "    #     config[\"per_sub_run_configs\"] = []\n",
    "\n",
    "    #     if pipeline_task:\n",
    "    #         config = pipeline_task.connect_configuration(config, name=\"config\")\n",
    "    for i_dataset in i_datasets:\n",
    "        sub_run_id = run_id + f\"_{i_dataset}\"\n",
    "        print(\"sub_run_id:\", sub_run_id)\n",
    "        #         sub_run_configs = {\"sub_run_id\": sub_run_id}\n",
    "\n",
    "        run_uris = TaskURIs(\n",
    "            project=project_name, pipeline_name=pipeline_name, run_id=sub_run_id\n",
    "        )\n",
    "\n",
    "        #         sub_run_configs[\"uris\"] = json.loads(json.dumps(vars(run_uris), default=str))\n",
    "\n",
    "        print(\"make dataset\")\n",
    "        training_dataset = make_new_dataset_component(\n",
    "            project=project_name, i_dataset=i_dataset, num_samples_per_chunk=500\n",
    "        )\n",
    "        #         sub_run_configs[\"uris\"][\"training_dataset\"] = {\n",
    "        #             \"id\": training_dataset.id,\n",
    "        #             \"name\": training_dataset.name,\n",
    "        #         }\n",
    "\n",
    "        for backbone_name, image_resize, batch_size in zip(backbone_names, image_resizes, batch_sizes):\n",
    "            print(\"train model\")\n",
    "            run_model_path, run_tb_path = train_image_classifier_component(\n",
    "                clearml_dataset=training_dataset,\n",
    "                backbone_name=backbone_name,\n",
    "                image_resize=image_resize,\n",
    "                batch_size=batch_size,\n",
    "                run_model_uri=run_uris.models,\n",
    "                run_tb_uri=run_uris.tboard,\n",
    "                local_data_path=\"/data\",\n",
    "                num_epochs=num_train_epochs,\n",
    "            )\n",
    "            #         sub_run_configs[\"uris\"][\"run_model_path\"] = str(run_model_path)\n",
    "\n",
    "            print(\"evaluate model\")\n",
    "            run_eval_path = eval_model_component(\n",
    "                run_learner_path=run_model_path,\n",
    "                run_id=sub_run_id,\n",
    "                dataset_name=\"pets_evaluation\",\n",
    "                dataset_project=\"lavi-testing\",\n",
    "                run_eval_uri=run_uris.evaluations,\n",
    "                image_resize=image_resize,\n",
    "                batch_size=int(batch_size * 1.5),\n",
    "                local_data_path=\"/data\",\n",
    "            )\n",
    "    #         sub_run_configs[\"uris\"][\"run_eval_path\"] = str(run_eval_path)\n",
    "    #         # clearml_task.close()\n",
    "    #         config[\"per_sub_run_configs\"].append(sub_run_configs)\n",
    "\n",
    "    print(\"pipeline complete\")\n",
    "\n",
    "    # return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d8ab2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%pdb on\n",
    "from datetime import datetime\n",
    "\n",
    "run_id = f\"run_{datetime.utcnow().strftime('%Y_%m_%dT%H_%M_%S.%f')[:-3]}\"\n",
    "PipelineDecorator.set_default_execution_queue(\"default\")\n",
    "#PipelineDecorator.run_locally()\n",
    "\n",
    "i_datasets = (0, 1, 2, 3)\n",
    "train_params = [\n",
    "    {\"backbone_name\": \"resnet34\", \"image_resize\": 128, \"batch_size\": 16},\n",
    "    {\"backbone_name\": \"efficientnetv2_rw_s\", \"image_resize\": 128, \"batch_size\": 16},\n",
    "    {\"backbone_name\": \"resnet34\", \"image_resize\": 128, \"batch_size\": 32},\n",
    "    {\"backbone_name\": \"efficientnetv2_rw_s\", \"image_resize\": 128, \"batch_size\": 32},\n",
    "    {\"backbone_name\": \"resnet34\", \"image_resize\": 224, \"batch_size\": 16},\n",
    "    {\"backbone_name\": \"efficientnetv2_rw_s\", \"image_resize\": 288, \"batch_size\": 16},\n",
    "]\n",
    "\n",
    "\n",
    "def ld2dl(LD):\n",
    "    return {k: [dic[k] for dic in LD] for k in LD[0]}\n",
    "\n",
    "\n",
    "train_params_dl = ld2dl(train_params)\n",
    "\n",
    "i_datasets = (0, 1)\n",
    "\n",
    "fastai_image_classification_pipeline(\n",
    "    run_id=run_id,\n",
    "    i_datasets=i_datasets,\n",
    "    backbone_names=train_params_dl[\"backbone_name\"],\n",
    "    image_resizes=train_params_dl[\"image_resize\"],\n",
    "    batch_sizes=train_params_dl[\"batch_size\"],\n",
    "    num_train_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbea268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from image_classifier_training.pipeline_functions import *\n",
    "# def fastai_image_classification(\n",
    "#     run_id: str,\n",
    "#     i_datasets: Tuple[int],\n",
    "#     backbone_name: str,\n",
    "#     image_resize: int,\n",
    "#     batch_size: int,\n",
    "#     num_train_epochs: int = 5,\n",
    "# ):\n",
    "#     from clearml import Task\n",
    "#     import json\n",
    "\n",
    "#     class TaskURIs:\n",
    "#         def __init__(self, project, pipeline_name, run_id):\n",
    "#             path_pref = f\"{project}/{pipeline_name}\"\n",
    "#             self.tboard = f\"{path_pref}/tboard/{run_id}\"\n",
    "#             self.models = f\"{path_pref}/models/{run_id}\"\n",
    "#             self.evaluations = f\"{path_pref}/evaluations/{run_id}\"\n",
    "\n",
    "#     project_name = \"lavi-testing\"\n",
    "#     pipeline_name = \"fastai_image_classification\"\n",
    "\n",
    "#     pipeline_task = Task.current_task()\n",
    "#     print(\"pipeline task=\", pipeline_task)\n",
    "#     #     config = {\"run_id\": run_id}\n",
    "#     #     config[\"backbone_name\"] = backbone_name\n",
    "#     #     config[\"i_datasets\"] = i_datasets\n",
    "\n",
    "#     #     config[\"per_sub_run_configs\"] = []\n",
    "\n",
    "#     #     if pipeline_task:\n",
    "#     #         config = pipeline_task.connect_configuration(config, name=\"config\")\n",
    "#     for i_dataset in i_datasets:\n",
    "#         sub_run_id = run_id + f\"_{i_dataset}\"\n",
    "#         print(\"sub_run_id:\", sub_run_id)\n",
    "#         #         sub_run_configs = {\"sub_run_id\": sub_run_id}\n",
    "\n",
    "#         run_uris = TaskURIs(\n",
    "#             project=project_name, pipeline_name=pipeline_name, run_id=sub_run_id\n",
    "#         )\n",
    "\n",
    "#         #         sub_run_configs[\"uris\"] = json.loads(json.dumps(vars(run_uris), default=str))\n",
    "\n",
    "#         print(\"make dataset\")\n",
    "#         training_dataset = make_new_dataset(\n",
    "#             project=project_name, i_dataset=i_dataset, num_samples_per_chunk=500\n",
    "#         )\n",
    "#         #         sub_run_configs[\"uris\"][\"training_dataset\"] = {\n",
    "#         #             \"id\": training_dataset.id,\n",
    "#         #             \"name\": training_dataset.name,\n",
    "#         #         }\n",
    "\n",
    "#         print(\"train model\")\n",
    "#         run_model_path, run_tb_path = train_image_classifier(\n",
    "#             clearml_dataset=training_dataset,\n",
    "#             backbone_name=backbone_name,\n",
    "#             image_resize=image_resize,\n",
    "#             batch_size=batch_size,\n",
    "#             run_model_uri=run_uris.models,\n",
    "#             run_tb_uri=run_uris.tboard,\n",
    "#             local_data_path=\"/data\",\n",
    "#             num_epochs=num_train_epochs,\n",
    "#         )\n",
    "#         #         sub_run_configs[\"uris\"][\"run_model_path\"] = str(run_model_path)\n",
    "\n",
    "#         print(\"evaluate model\")\n",
    "#         run_eval_path = eval_model(\n",
    "#             run_learner_path=run_model_path,\n",
    "#             run_id=sub_run_id,\n",
    "#             dataset_name=\"pets_evaluation\",\n",
    "#             dataset_project=\"lavi-testing\",\n",
    "#             run_eval_uri=run_uris.evaluations,\n",
    "#             image_resize=image_resize,\n",
    "#             local_data_path=\"/data\",\n",
    "#         )\n",
    "#     #         sub_run_configs[\"uris\"][\"run_eval_path\"] = str(run_eval_path)\n",
    "#     #         # clearml_task.close()\n",
    "#     #         config[\"per_sub_run_configs\"].append(sub_run_configs)\n",
    "\n",
    "#     print(\"pipeline complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973bb6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from image_classifier_training.pipeline_functions import *\n",
    "# def fastai_image_classification(\n",
    "#     run_id: str,\n",
    "#     i_datasets: Tuple[int],\n",
    "#     backbone_name: str,\n",
    "#     image_resize: int,\n",
    "#     batch_size: int,\n",
    "#     num_train_epochs: int = 5,\n",
    "# ):\n",
    "#     from clearml import Task\n",
    "#     import json\n",
    "\n",
    "#     class TaskURIs:\n",
    "#         def __init__(self, project, pipeline_name, run_id):\n",
    "#             path_pref = f\"{project}/{pipeline_name}\"\n",
    "#             self.tboard = f\"{path_pref}/tboard/{run_id}\"\n",
    "#             self.models = f\"{path_pref}/models/{run_id}\"\n",
    "#             self.evaluations = f\"{path_pref}/evaluations/{run_id}\"\n",
    "\n",
    "#     project_name = \"lavi-testing\"\n",
    "#     pipeline_name = \"fastai_image_classification\"\n",
    "\n",
    "#     pipeline_task = Task.current_task()\n",
    "#     print(\"pipeline task=\", pipeline_task)\n",
    "#     #     config = {\"run_id\": run_id}\n",
    "#     #     config[\"backbone_name\"] = backbone_name\n",
    "#     #     config[\"i_datasets\"] = i_datasets\n",
    "\n",
    "#     #     config[\"per_sub_run_configs\"] = []\n",
    "\n",
    "#     #     if pipeline_task:\n",
    "#     #         config = pipeline_task.connect_configuration(config, name=\"config\")\n",
    "#     for i_dataset in i_datasets:\n",
    "#         sub_run_id = run_id + f\"_{i_dataset}\"\n",
    "#         print(\"sub_run_id:\", sub_run_id)\n",
    "#         #         sub_run_configs = {\"sub_run_id\": sub_run_id}\n",
    "\n",
    "#         run_uris = TaskURIs(\n",
    "#             project=project_name, pipeline_name=pipeline_name, run_id=sub_run_id\n",
    "#         )\n",
    "\n",
    "#         #         sub_run_configs[\"uris\"] = json.loads(json.dumps(vars(run_uris), default=str))\n",
    "\n",
    "#         print(\"make dataset\")\n",
    "#         training_dataset = make_new_dataset(\n",
    "#             project=project_name, i_dataset=i_dataset, num_samples_per_chunk=500\n",
    "#         )\n",
    "#         #         sub_run_configs[\"uris\"][\"training_dataset\"] = {\n",
    "#         #             \"id\": training_dataset.id,\n",
    "#         #             \"name\": training_dataset.name,\n",
    "#         #         }\n",
    "\n",
    "#         print(\"train model\")\n",
    "#         run_model_path, run_tb_path = train_image_classifier(\n",
    "#             clearml_dataset=training_dataset,\n",
    "#             backbone_name=backbone_name,\n",
    "#             image_resize=image_resize,\n",
    "#             batch_size=batch_size,\n",
    "#             run_model_uri=run_uris.models,\n",
    "#             run_tb_uri=run_uris.tboard,\n",
    "#             local_data_path=\"/data\",\n",
    "#             num_epochs=num_train_epochs,\n",
    "#         )\n",
    "#         #         sub_run_configs[\"uris\"][\"run_model_path\"] = str(run_model_path)\n",
    "\n",
    "#         print(\"evaluate model\")\n",
    "#         run_eval_path = eval_model(\n",
    "#             run_learner_path=run_model_path,\n",
    "#             run_id=sub_run_id,\n",
    "#             dataset_name=\"pets_evaluation\",\n",
    "#             dataset_project=\"lavi-testing\",\n",
    "#             run_eval_uri=run_uris.evaluations,\n",
    "#             image_resize=image_resize,\n",
    "#             local_data_path=\"/data\",\n",
    "#         )\n",
    "#     #         sub_run_configs[\"uris\"][\"run_eval_path\"] = str(run_eval_path)\n",
    "#     #         # clearml_task.close()\n",
    "#     #         config[\"per_sub_run_configs\"].append(sub_run_configs)\n",
    "\n",
    "#     print(\"pipeline complete\")\n",
    "\n",
    "# from datetime import datetime\n",
    "\n",
    "# run_id = f\"run_{datetime.utcnow().strftime('%Y_%m_%dT%H_%M_%S.%f')[:-3]}\"\n",
    "# # PipelineDecorator.set_default_execution_queue(\"default\")\n",
    "# PipelineDecorator.run_locally()\n",
    "\n",
    "# # i_datasets = (0,1,2,3)\n",
    "# # backbones = [\"resvent\"]\n",
    "# # train_params = [{\n",
    "# #     \"backbone_name\": \"resnet34\"\n",
    "# #     \"image_resize\": 224\n",
    "\n",
    "# # }]\n",
    "# i_datasets = (0, 1)\n",
    "\n",
    "# fastai_image_classification(\n",
    "#     run_id=run_id,\n",
    "#     i_datasets=i_datasets,\n",
    "#     backbone_name=\"efficientnetv2_rw_s\",\n",
    "#     image_resize=288,\n",
    "#     batch_size=16,\n",
    "#     num_train_epochs=5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9dcd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485e2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbec344",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e461c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03f4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70797396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm \n",
    "import torch\n",
    "\n",
    "model = timm.create_model('efficientnetv2_rw_s')\n",
    "x     = torch.randn(1, 3, 224, 224)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47476c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "?PipelineDecorator.run_locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108ad5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
